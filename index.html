<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" xml:lang="en"><head>
    <!-- Global site tag (gtag.js) - Google Analytics -->
    <script async src="https://www.googletagmanager.com/gtag/js?id=UA-122759872-1"></script>
    <script>
        window.dataLayer = window.dataLayer || [];
        function gtag(){dataLayer.push(arguments);}
        gtag('js', new Date());
        
        gtag('config', 'UA-122759872-1');
        </script>

    <meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
        <link rel="shortcut icon" HREF="index/github_logo.png">
            <title>Ziyi Zhang</title>
            <link rel="stylesheet" type="text/css" href="./index/main.css">
                <link href="./index/css" rel="stylesheet">
                    <style>
                        .quote{
                            font-family: 'Dawning of a New Day';
                            font-weight:bold;
                            font-size:30px;
                        }
                    </style>

</head>

<body>
    <div id="main">

        <div>
            <img src="./index/ZiyiZhang.jpg" style="width:200px; height:280px" class="portrait"><br>

                <div class="bio_format">
					<br>
					<p>
						<b style="font-size:25px;font-family:verdana;">Ziyi Zhang</b> &nbsp;
                        <a style="font-size:15px" href="https://github.com/ZiyiZhang27"><img src="index/github_logo.png" width="15px"> GitHub</a>
                        <b style="font-size:15px">|</b>
                        <a style="font-size:15px" href="https://scholar.google.com/citations?&user=w5_uQyoAAAAJ"><img src="index/google_logo.png" width="15px"> Google Scholar</a>
                        <b style="font-size:15px">|</b>
                        <a style="font-size:15px" href="https://orcid.org/0000-0003-1728-2588"><img src="index/orcid_logo.png" width="15px"> ORCID</a>
						<br>

						<b style="font-size:15px"><img src="index/email.png" width="15px"> ziyizhang27@whu.edu.cn</b>
                        <br>
                        <br>
                        I am currently a Ph.D. student in <i><a href="http://sigma.whu.edu.cn/">Sensing IntelliGence and MAchine learning lab (SIGMA)</a></i> at <i><a href="https://cs.whu.edu.cn/">School of Computer Science, Wuhan University (WHU)</a></i>, advised by <a href="https://cs.whu.edu.cn/info/1019/2856.htm">Professor Yong Luo</a>.
                        <br>
                        <br>
                        Previously, I obtained my Master's degree from <i><a href="https://cs.njupt.edu.cn/">School of Computer Science, Nanjing University of Posts and Telecommunications (NJUPT)</a></i>, where I was advised by <a href="https://yjs.njupt.edu.cn/dsgl/nocontrol/college/dsfcxq.htm?dsJbxxId=9BE0C75DC6137A6AE050007F01001C3A">Professor Qun Li</a>.
                        In addition to my academic experience, I was fortunate to have spent a productive internship at <i><a>ByteDance - Pico</a></i> in 2022.
                    </p>
                </div>
        </div>


		<div>
		    <span class="category">Research Interests</span>
            <hr class="line">
			<span class="content2_format">
			    <p> I am currently interested in Generative Models, particularly in Text-to-Image and Text-to-3D synthesis, as well as Reinforcement Learning. </p>
			</span>
		</div>


        <div>
            <span class="category">Publications</span>
            <hr class="line">
            <ol style="padding:0px;list-style-type:none">

                <li class="item_format" style="position:relative">
                    <img src="index/mvczigal.png" class="img_format">
                    <div class="title_format">
                        <b><a style="color: #F4606C" href="https://arxiv.org/abs/2505.20107">Refining Few-Step Text-to-Multiview Diffusion via Reinforcement Learning</a></b>
                        <span class="author_format"> <b>Ziyi Zhang</b>, Li Shen, Deheng Ye, Yong Luo, Huangxuan Zhao, Lefei Zhang </span>
                        <span class="conference_format"> <i style="color: #4994c4">arXiv preprint</i>, 2025 </span>
                        <div class="link_format">
                            [<a href="https://arxiv.org/pdf/2505.20107">PDF</a>]
                            [<a href="https://github.com/ZiyiZhang27/MVC-ZigAL">Code</a>]
                        </div>
                    </div>
                    <div style="clear:both;"></div>
                </li>

                <li class="item_format" style="position:relative">
                    <img src="index/SDPO.png" class="img_format">
                    <div class="title_format">
                        <b><a style="color: #F4606C" href="https://arxiv.org/abs/2411.11727">Aligning Few-Step Diffusion Models with Dense Reward Difference Learning</a></b>
                        <span class="author_format"> <b>Ziyi Zhang</b>, Li Shen, Sen Zhang, Deheng Ye, Yong Luo, Miaojing Shi, Bo Du, Dacheng Tao </span>
                        <span class="conference_format"> <i style="color: #4994c4">arXiv preprint</i>, 2024 </span>
                        <div class="link_format">
                            [<a href="https://arxiv.org/pdf/2411.11727">PDF</a>]
                            [<a href="https://github.com/ZiyiZhang27/sdpo">Code</a>]
                        </div>
                    </div>
                    <div style="clear:both;"></div>
                </li>

                <li class="item_format" style="position:relative">
                    <img src="index/tdpo.png" class="img_format">
                    <div class="title_format">
                        <b><a style="color: #F4606C" href="https://icml.cc/virtual/2024/poster/32798">Confronting Reward Overoptimization for Diffusion Models: A Perspective of Inductive and Primacy Biases</a></b>
                        <span class="author_format"> <b>Ziyi Zhang</b>, Sen Zhang, Yibing Zhan, Yong Luo, Yonggang Wen, Dacheng Tao </span>
                        <span class="conference_format"> <i style="color: #4994c4">International Conference on Machine Learning (ICML)</i>, 2024 </span>
                        <div class="link_format">
                            [<a href="https://openreview.net/pdf?id=v2o9rRJcEv">PDF</a>]
                            [<a href="https://github.com/ZiyiZhang27/tdpo">Code</a>]
                        </div>
                    </div>
                    <div style="clear:both;"></div>
                </li>

				<li class="item_format" style="position:relative">
                    <img src="index/HRNeXt.png" class="img_format">
                    <div class="title_format">
                        <b><a style="color: #F4606C" href="https://doi.org/10.1109/TMM.2023.3248144">HRNeXt: High-Resolution Context Network for Crowd Pose Estimation</a></b>
                        <span class="author_format"> Qun Li, <b>Ziyi Zhang</b>, Feng Zhang, Fu Xiao </span>
                        <span class="conference_format"> <i style="color: #4994c4">IEEE Transactions on Multimedia (IEEE TMM)</i>, 2023 </span>
                        <div class="link_format">
                            [<a href="https://doi.org/10.1109/TMM.2023.3248144">PDF</a>]
                            [<a href="https://github.com/ZiyiZhang27/HRNeXt">Code</a>]
                        </div>
                    </div>
                    <div style="clear:both;"></div>
                </li>

                <li class="item_format" style="position:relative">
                    <img src="index/Dite-HRNet.png" class="img_format">
                    <div class="title_format">
                        <b><a style="color: #F4606C" href="https://www.ijcai.org/proceedings/2022/153">Dite-HRNet: Dynamic Lightweight High-Resolution Network for Human Pose Estimation</a></b>
                        <span class="author_format"> Qun Li, <b>Ziyi Zhang</b>, Fu Xiao, Feng Zhang, Bir Bhanu </span>
                        <span class="conference_format"> <i style="color: #4994c4">International Joint Conference on Artificial Intelligence (IJCAI)</i>, 2022 </span>
                        <div class="link_format">
                            [<a href="https://www.ijcai.org/proceedings/2022/0153.pdf">PDF</a>]
                            [<a href="https://github.com/ZiyiZhang27/Dite-HRNet">Code</a>]
                            [<a href="https://www.ijcai.org/proceedings/2022/video/0153">Video</a>]
                        </div>
                    </div>
                    <div style="clear:both;"></div>
                </li>

                <li class="item_format" style="position:relative">
                    <div class="title_format">
                        <b><a style="color: black" href="https://www.sciencedirect.com/science/article/abs/pii/S0952197623018262">Dynamic Context Modeling Based Lightweight High-Resolution Network for Dense Prediction</a></b>
                        <span class="author_format"> Baoquan Sun, Qun Li, <b>Ziyi Zhang</b> </span>
                        <span class="conference_format"> <i>Engineering Applications of Artificial Intelligence (EAAI)</i>, 2024 </span>
                    </div>
                    <div style="clear:both;"></div>
                </li>

				<li class="item_format" style="position:relative">
                    <div class="title_format">
                        <b><a style="color: black" href="https://ieeexplore.ieee.org/document/10240970">Dual-Branch Framework with Convolutional Attentive Block for Video Anomaly Detection</a></b>
                        <span class="author_format"> Qun Li, Rui Yang, Yaying Shen, <b>Ziyi Zhang</b>, Xianzhong Long </span>
                        <span class="conference_format"> <i>Chinese Control Conference (CCC)</i>, 2023 </span>
                    </div>
                    <div style="clear:both;"></div>
                </li>

                <li class="item_format" style="position:relative">
                    <div class="title_format">
                        <b><a style="color: black" href="https://ieeexplore.ieee.org/document/9892924"> Anomaly Detection in Surveillance Videos via Memory-augmented Frame Prediction</a></b>
                        <span class="author_format"> Rui Yang, Qun Li, Yaying Shen, <b>Ziyi Zhang</b> </span>
                        <span class="conference_format"> <i>International Joint Conference on Neural Networks (IJCNN)</i>, 2022 </span>
                    </div>
                    <div style="clear:both;"></div>
                </li>

                <li class="item_format" style="position:relative">
                    <div class="title_format">
                        <b><a style="color: black" href="https://search.ieice.org/bin/summary.php?id=e105-d_4_832">Triple Loss Based Framework for Generalized Zero-Shot Learning</a></b>
                        <span class="author_format"> Yaying Shen, Qun Li, Ding Xu, <b>Ziyi Zhang</b>, Rui Yang </span>
                        <span class="conference_format"> <i>IEICE Transactions on Information and Systems</i>, 2022 </span>
                    </div>
                    <div style="clear:both;"></div>
                </li>

                <li class="item_format" style="position:relative">
                    <div class="title_format">
                        <b><a style="color: black" href="https://www.jos.org.cn/josen/article/abstract/6621">Video Summarization Based on Spacial-temporal Transform Network</a></b>
                        <span class="author_format"> Qun Li, Fu Xiao, <b>Ziyi Zhang</b>, Feng Zhang, Yanchao Li </span>
                        <span class="conference_format"> <i>Journal of Software</i>, 2022 </span>
                    </div>
                    <div style="clear:both;"></div>
                </li>

            </ol>
        </div>


        <div>
            <span class="category">Academic Services</span>
            <hr class="line">
            <span class="content2_format">
                <p> <b>Reviewer</b>: <i>NeurIPS 2025</i>, <i>IEEE TMM</i>, <i>Pattern Recognition</i>, <i>Machine Intelligence Research</i>, <i>ICPR 2024</i>, <i>ICDM 2024</i> </p>
            </span>
        </div>


        <div>
            <span class="category">Awards</span>
            <hr class="line">
            <span class="content2_format">
                <p>
                    <li> Huawei Scholarship of <i style="color: #4994c4">WHU</i>, 2024 </li>
                    <li> The Second Prize Scholarship of <i style="color: #4994c4">WHU</i>, 2024 </li>
                    <li style="color: #F4606C"> Outstanding Master's Thesis of <i style="color: #4994c4">Jiangsu Province</i>, 2024 </li>
                    <li> Outstanding Graduate of <i style="color: #4994c4">NJUPT</i>, 2023 </li>
                    <li style="color: #F4606C"> China National Scholarship, 2022 </li>
                    <li> Excellent Graduate Student Scholarship of <i style="color: #4994c4">NJUPT</i>, 2022 </li>
                    <li> The First Prize Scholarship of <i style="color: #4994c4">NJUPT</i>, 2022 </li>
                    <li> The First Prize Scholarship of <i style="color: #4994c4">NJUPT</i>, 2021 </li>
                    <li> The Second Prize Scholarship of <i style="color: #4994c4">NJUPT</i>, 2020 </li>
                </p>
            </span>
        </div>


    </div>


	<!-- <script  src="./index/script.js"></script> -->
	<!-- <canvas z-index: -1;></canvas> -->
	<script src="./index/script.js" opacity="0.6" color="0,68,255" zindex="-1"></script>
	<canvas id="c_n1" width="1287" height="736" style="position: fixed; top: 0px; left: 0px; z-index: -1; opacity: 1;" ></canvas>


    <!-- <script src="./index/canvas-nest.js_1.0.1_canvas-nest.min.js" opacity="0.6" color="0,68,255" zindex="-1"></script><canvas id="c_n1" width="1287" height="736" style="position: fixed; top: 0px; left: 0px; z-index: -1; opacity: 0.6;"></canvas> -->

</body></html>
